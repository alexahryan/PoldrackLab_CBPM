{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63418f08-b6fc-4458-9102-f88c9483fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ac5d3-1bd4-4d6a-9ff4-fc55a2dd6a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the input to this code will be a set of fc matrices, stored as .txt or .csv files in a directory called fc_data\n",
    "top_dir = Path(\"./\")\n",
    "data_dir = top_dir/\"fc_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cc4fa-51b5-43de-a29e-2101a40eb4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the sample\n",
    "#need to change the title of the text file\n",
    "subj_list = pd.read_csv('DATA.txt', header=None)\n",
    "subj_list = np.array(subj_list, dtype=str).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddc1c9-2871-4fce-90be-9d3a1d058975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in behavioral data\n",
    "#need to change the title of file\n",
    "all_behav_data = pd.read_csv('BEHAVIORAL_DATA.csv', dtype={'Subject': str})\n",
    "all_behav_data.set_index('Subject', inplace=True)\n",
    "print(all_behav_data.shape)\n",
    "all_behav_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abad12-d880-4f0d-9acd-37bc029765dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for reading in individual-subject connectivity matrices\n",
    "def read_in_matrices(subj_list, file_suffix=None, data_dir=data_dir, zscore=False):\n",
    "    \"\"\"\n",
    "    Reads in a set of individual-subject connectivity matrices stored in data_dir,\n",
    "    \n",
    "    Returns a dataframe that is subjects x edges (by vectorizing the upper triangle of each FC matrix).\n",
    "    \n",
    "    Assumes:\n",
    "    - each matrix is stored in a separate file beginning with the subject ID, and\n",
    "    - matrices are symmetric (squareform); i.e., for a parcellation with 268 nodes, matrices should be 268 x 268\n",
    "    \"\"\"\n",
    "    \n",
    "    all_fc_data = {}\n",
    "            \n",
    "    for subj in subj_list:\n",
    "        # try to find this subject's matrix\n",
    "        if file_suffix:\n",
    "            file = [f for f in os.listdir(data_dir) if subj in f and file_suffix in f]\n",
    "        else:\n",
    "            file = [f for f in os.listdir(data_dir) if subj in f]\n",
    "            \n",
    "        # make sure there is one and only one file    \n",
    "        if len(file) ==0:\n",
    "            raise ValueError(\"No data found for subject {}\".format(subj))\n",
    "        if len(file) >1:\n",
    "            raise ValueError(\"More than one matrix found for subject {}! Specify a suffix?\".format(subj))\n",
    "        \n",
    "        # read it in and make sure it's symmetric and has reasonable dimensions\n",
    "        tmp = np.loadtxt(data_dir / file[0])\n",
    "        assert tmp.shape[0]==tmp.shape[1]>1, \"Matrix seems to have incorrect dimensions: {}\".format(tmp.shape)\n",
    "        \n",
    "        # take just the upper triangle and store it in a dictionary\n",
    "        if ~zscore:\n",
    "            all_fc_data[subj] = tmp[np.triu_indices_from(tmp, k=1)]\n",
    "        if zscore:\n",
    "            all_fc_data[subj] = sp.stats.zscore(tmp[np.triu_indices_from(tmp, k=1)])\n",
    "        \n",
    "    # Convert dictionary into dataframe\n",
    "    all_fc_data = pd.DataFrame.from_dict(all_fc_data, orient='index')\n",
    "    \n",
    "    return all_fc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2aa8e-6ccc-4f4e-a996-104a14ff17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fc_data = read_in_matrices(subj_list, file_suffix='REST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13114336-8572-48ef-831d-67d37d670937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that dataframe looks reasonable\n",
    "print(all_fc_data.shape)\n",
    "all_fc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5389c65-ebc8-497d-ad08-7381caad3af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bfbdb7-950f-4735-9f1b-21f6edc7a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define CPM functions\n",
    "def mk_kfold_indices(subj_list, k = 10):\n",
    "    \"\"\"\n",
    "    Splits list of subjects into k folds for cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_subs = len(subj_list)\n",
    "    n_subs_per_fold = n_subs//k # floor integer for n_subs_per_fold\n",
    "\n",
    "    indices = [[fold_no]*n_subs_per_fold for fold_no in range(k)] # generate repmat list of indices\n",
    "    remainder = n_subs % k # figure out how many subs are left over\n",
    "    remainder_inds = list(range(remainder))\n",
    "    indices = [item for sublist in indices for item in sublist]    \n",
    "    [indices.append(ind) for ind in remainder_inds] # add indices for remainder subs\n",
    "\n",
    "    assert len(indices)==n_subs, \"Length of indices list does not equal number of subjects, something went wrong\"\n",
    "\n",
    "    np.random.shuffle(indices) # shuffles in place\n",
    "\n",
    "    return np.array(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb88fe1a-f039-47e1-bd5d-aac85da2cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(all_fc_data, train_subs, test_subs, behav_data, behav):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts requested FC and behavioral data for a list of train_subs and test_subs\n",
    "    \"\"\"\n",
    "\n",
    "    train_vcts = all_fc_data.loc[train_subs, :]\n",
    "    test_vcts = all_fc_data.loc[test_subs, :]\n",
    "\n",
    "    train_behav = behav_data.loc[train_subs, behav]\n",
    "\n",
    "    return (train_vcts, train_behav, test_vcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0415a77-571c-401d-9b60-a6a37b8ea6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(train_vcts, train_behav, r_thresh=0.2, corr_type='pearson', verbose=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs the CPM feature selection step: \n",
    "    - correlates each edge with behavior, and returns a mask of edges that are correlated above some threshold, one for each tail (positive and negative)\n",
    "    \"\"\"\n",
    "\n",
    "    assert train_vcts.index.equals(train_behav.index), \"Row indices of FC vcts and behavior don't match!\"\n",
    "\n",
    "    # Correlate all edges with behav vector\n",
    "    if corr_type =='pearson':\n",
    "        cov = np.dot(train_behav.T - train_behav.mean(), train_vcts - train_vcts.mean(axis=0)) / (train_behav.shape[0]-1)\n",
    "        corr = cov / np.sqrt(np.var(train_behav, ddof=1) * np.var(train_vcts, axis=0, ddof=1))\n",
    "    elif corr_type =='spearman':\n",
    "        corr = []\n",
    "        for edge in train_vcts.columns:\n",
    "            r_val = sp.stats.spearmanr(train_vcts.loc[:,edge], train_behav)[0]\n",
    "            corr.append(r_val)\n",
    "\n",
    "    # Define positive and negative masks\n",
    "    mask_dict = {}\n",
    "    mask_dict[\"pos\"] = corr > r_thresh\n",
    "    mask_dict[\"neg\"] = corr < -r_thresh\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Found ({}/{}) edges positively/negatively correlated with behavior in the training set\".format(mask_dict[\"pos\"].sum(), mask_dict[\"neg\"].sum())) # for debugging\n",
    "\n",
    "    return mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de15e8-dbf0-4dcd-b32d-c359b0b14da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train_vcts, mask_dict, train_behav):\n",
    "    \"\"\"\n",
    "    Builds a CPM model:\n",
    "    - takes a feature mask, sums all edges in the mask for each subject, and uses simple linear regression to relate summed network strength to behavior\n",
    "    \"\"\"\n",
    "\n",
    "    assert train_vcts.index.equals(train_behav.index), \"Row indices of FC vcts and behavior don't match!\"\n",
    "\n",
    "    model_dict = {}\n",
    "\n",
    "    # Loop through pos and neg tails\n",
    "    X_glm = np.zeros((train_vcts.shape[0], len(mask_dict.items())))\n",
    "\n",
    "    t = 0\n",
    "    for tail, mask in mask_dict.items():\n",
    "        X = train_vcts.values[:, mask].sum(axis=1)\n",
    "        X_glm[:, t] = X\n",
    "        y = train_behav\n",
    "        (slope, intercept) = np.polyfit(X, y, 1)\n",
    "        model_dict[tail] = (slope, intercept)\n",
    "        t+=1\n",
    "\n",
    "    X_glm = np.c_[X_glm, np.ones(X_glm.shape[0])]\n",
    "    model_dict[\"glm\"] = tuple(np.linalg.lstsq(X_glm, y, rcond=None)[0])\n",
    "\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da16d3-72d3-4823-a6a5-da751f37c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(test_vcts, mask_dict, model_dict):\n",
    "    \"\"\"\n",
    "    Applies a previously trained linear regression model to a test set to generate predictions of behavior.\n",
    "    \"\"\"\n",
    "\n",
    "    behav_pred = {}\n",
    "\n",
    "    X_glm = np.zeros((test_vcts.shape[0], len(mask_dict.items())))\n",
    "\n",
    "    # Loop through pos and neg tails\n",
    "    t = 0\n",
    "    for tail, mask in mask_dict.items():\n",
    "        X = test_vcts.loc[:, mask].sum(axis=1)\n",
    "        X_glm[:, t] = X\n",
    "\n",
    "        slope, intercept = model_dict[tail]\n",
    "        behav_pred[tail] = slope*X + intercept\n",
    "        t+=1\n",
    "\n",
    "    X_glm = np.c_[X_glm, np.ones(X_glm.shape[0])]\n",
    "    behav_pred[\"glm\"] = np.dot(X_glm, model_dict[\"glm\"])\n",
    "\n",
    "    return behav_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bab70-41d8-43a6-9889-f019672175f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine above functions into a wrapper function\n",
    "def cpm_wrapper(all_fc_data, all_behav_data, behav, k=10, **cpm_kwargs):\n",
    "\n",
    "    assert all_fc_data.index.equals(all_behav_data.index), \"Row (subject) indices of FC vcts and behavior don't match!\"\n",
    "\n",
    "    subj_list = all_fc_data.index # get subj_list from df index\n",
    "    \n",
    "    indices = mk_kfold_indices(subj_list, k=k)\n",
    "    \n",
    "    # Initialize df for storing observed and predicted behavior\n",
    "    col_list = []\n",
    "    for tail in [\"pos\", \"neg\", \"glm\"]:\n",
    "        col_list.append(behav + \" predicted (\" + tail + \")\")\n",
    "    col_list.append(behav + \" observed\")\n",
    "    behav_obs_pred = pd.DataFrame(index=subj_list, columns = col_list)\n",
    "    \n",
    "    # Initialize array for storing feature masks\n",
    "    n_edges = all_fc_data.shape[1]\n",
    "    all_masks = {}\n",
    "    all_masks[\"pos\"] = np.zeros((k, n_edges))\n",
    "    all_masks[\"neg\"] = np.zeros((k, n_edges))\n",
    "    \n",
    "    for fold in range(k):\n",
    "        print(\"doing fold {}\".format(fold))\n",
    "        train_subs, test_subs = split_train_test(subj_list, indices, test_fold=fold)\n",
    "        train_vcts, train_behav, test_vcts = get_train_test_data(all_fc_data, train_subs, test_subs, all_behav_data, behav=behav)\n",
    "        mask_dict = select_features(train_vcts, train_behav, **cpm_kwargs)\n",
    "        all_masks[\"pos\"][fold,:] = mask_dict[\"pos\"]\n",
    "        all_masks[\"neg\"][fold,:] = mask_dict[\"neg\"]\n",
    "        model_dict = build_model(train_vcts, mask_dict, train_behav)\n",
    "        behav_pred = apply_model(test_vcts, mask_dict, model_dict)\n",
    "        for tail, predictions in behav_pred.items():\n",
    "            behav_obs_pred.loc[test_subs, behav + \" predicted (\" + tail + \")\"] = predictions\n",
    "            \n",
    "    behav_obs_pred.loc[subj_list, behav + \" observed\"] = all_behav_data[behav]\n",
    "    \n",
    "    return behav_obs_pred, all_masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
